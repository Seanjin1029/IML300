<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Sean's Thoughts</title>
    <link rel="stylesheet" href="indexstyle.css" />
  </head>
  <body class="Thoughts">
    <p>
      Jenny Odell’s How to Internet spotlights the evolution of community and
      relationship between strangers on the internet. Odell reminiscences on the
      feeling of connection with strangers online due to the internet’s smaller
      size. She provides examples of these encounters, recalling one interaction
      with a stranger from Russia on Second life, an online virtual world game
      from the mid-2000s. Odell contrasts these coincidental, random experiences
      to today’s algorithm based filtered content. I definitely sympathize with
      Odell’s longing for this “old” internet as my childhood consisted of
      online avatar games, random Korean game websites, and “how to internet”
      videos that I would not be able to stumble across today. Lauren Schwult’s,
      My website is a shifting house next to a river of knowledge. What could
      yours be?, goes into depth on the practicalities and implications of a
      website. Schwult uses metaphors to break down certain attributes to a
      website, comparing a site to multiple tangible and physical objects, such
      as a room, a shelf, a plant, etc.. Though Schwult’s use of metaphors form
      a stark contrast between the internet and the physical world it somehow
      simultaneously merges the two together. This unification of these two
      dissimilar ideas make this article that much more intriguing. Is today’s
      algorithm-based, filtered, and specified internet more favorable than the
      older, random, and less catered-to internet favored by Odell? Obviously,
      today’s internet is a product of growing consumer tendencies, but do the
      pros of navigability and ease of use outweigh the pros of the “old”
      internet’s communal environment and overall connectability? Would you say
      “trolls” are a byproduct of/encouraged by the internet’s anonymity? What
      else could you see the internet evolving into, considering the increase in
      popularity and ease of access of virtual reality .
    </p>
    <p>
      Archiving a Revolution in the Digital Age, Archiving as an Act of
      Resistance by Lara Baladi does a great job of explaining the archive
      movement that occurred during the 2011 Egypt Revolution. Baladi focuses on
      the 18 days of revolution in Tahrir Square, one of the most "documented
      and mediatized events in the digital age". The extreme amount of
      documentation in Tahrir Square led to revolutionary artists continuing
      this weaponization of archiving and art after the 18 days in Tahrir
      Square. Artists were revolutionizing how, when, and where they worked and
      also which mediums they worked with. People began experimenting with more
      visual and performative arts out on the streets of Cairo and others
      decided to graffiti walls of significant locations as a finger to the
      oppressive state. This movement inevitably broadcasted the events of the
      Egypt Revolution to the rest of the world, spreading revolutionary art to
      people on the other side of the globe. Peter Soulellis’ talk relates to
      the first article, aforementioned, exploring the concept of the art in
      limited/oppressed states. Peter talks about queer art and the different
      design languages and overall aesthetics that can be used to empower lgbtq+
      movements. He relates these ideas back to personal experiences as a queer
      man and stresses the importance of design and media in any sort of
      movement. What would have happened if the 18 days in Tahrir Square had not
      been archived as it had been? Do limitations push artists to become more
      creative? Would you say that art is revolutionized more so by
      limitations/restrictions than without?
    </p>
    <p>
      I’ve always visualized the internet as something intangible and almost
      abstract, however, the video definitely helps put things into perspective
      and makes it much easier to visualize how everything works. I guess I
      thought I would be more surprised when hearing that DARPA was one of the
      first on the concept of the internet, but seeing as this all happened in
      the 1950s after wwii, I’m not as shocked. It is weird thinking of how
      women, such as Mary Anne Wilkes, Betty Jean Jennings, and Fran Bilas, some
      of the first “computer girls” were swept under the rug by history, and now
      computer science is a grossly male dominated field. I guess I wouldn’t
      expect much more from the states though. Reading #4 Black Gooey Universe
      by American Artist concerns the dominance of whitepeople and its
      consequences on Silicon Valley and the development of GUIs and computers
      overall. American Artist explains the commercialization of the internet
      and the push for anti-black products, the most prominent example being the
      Apple Lisa. The Apple Lisa was the first computer with a GUI,changing the
      monitor screen from black to white. This change in the 1970s represented
      the erasure of blackness and installation of whiteness, in its place. The
      second article, Rich User Experience, UX and Desktopnization of War, Olia
      Lialina writes about the quickly evolving meaning of UX/User Interface.
      Don Norman, the creator of the idea of UX recalled in 2007, “Since then
      the term has spread widely, so that it is starting to lose its meaning”.
      Nowadays, UX is mainly used to hide programmability and customizability,
      detaching the user from the computer and/or the reason the person may be
      on the computer. For example, the use of UX to dehumanize human targets in
      order to reduce ptsd for drone pilots, is an example of UX being used to
      detach the user from the computer/action. Aside from the change from a
      black screen to white screen, what are some ways in which the tech
      industry has favored whiteness over blackness? Is there any way to fix
      this issue? Do the pros of UX/User Interface/Experience outweigh the cons?
    </p>
    <p>
      Black Gooey Universe by American Artist concerns the dominance of
      whitepeople and its consequences on Silicon Valley and the development of
      GUIs and computers overall. American Artist explains the commercialization
      of the internet and the push for anti-black products, the most prominent
      example being the Apple Lisa. The Apple Lisa was the first computer with a
      GUI,changing the monitor screen from black to white. This change in the
      1970s represented the erasure of blackness and installation of whiteness,
      in its place. The second article, Rich User Experience, UX and
      Desktopnization of War, Olia Lialina writes about the quickly evolving
      meaning of UX/User Interface. Don Norman, the creator of the idea of UX
      recalled in 2007, “Since then the term has spread widely, so that it is
      starting to lose its meaning”. Nowadays, UX is mainly used to hide
      programmability and customizability, detaching the user from the computer
      and/or the reason the person may be on the computer. For example, the use
      of UX to dehumanize human targets in order to reduce ptsd for drone
      pilots, is an example of UX being used to detach the user from the
      computer/action. Aside from the change from a black screen to white
      screen, what are some ways in which the tech industry has favored
      whiteness over blackness? Is there any way to fix this issue? Do the pros
      of UX/User Interface/Experience outweigh the cons?
    </p>
    <p>
      Heather Dewey-Hagborg’s talk, I Steal DNA From Strangers, concerns the
      ease at which strangers can steal your DNA, gaining access to personal
      information only accessible through biological matter. Hagborg presents a
      series of theirs in which they picked up random pieces of gum and such in
      order to recreate facial structures based on the DNA left on that gum,
      displaying the amount of information able to be pulled from DNA. They go
      on to explain “Biononymous”, two sprays that work to erase and replace
      your DNA (essentially bleaching and spraying other DNA on any surface you
      contact), yet, I feel no need to create/use this spray whatsoever. Though
      this could be of genuine concern in the future, technology is not yet
      developed enough to where somebody’s DNA could be used against them.
      Lauren McCarthy’s Feeling Home is where more of my concerns arise,
      however. Surveillance and misuse of technology should be amongst the top
      concerns of every citizen right now. McCarthy mentioned how Amazon’s Alexa
      monitored conversations unwarranted and incidents in which abusers have
      controlled victims through security systems/home-appliance systems.
      Privacy and security should not be exchanged in order for minor
      conveniences, with the exception of disabled peoples and certain tasks.
      What is an example of a task that justifiably exchanges privacy for
      convenience? How should citizens navigate this thin line between privacy
      and convenience? Considering Amazon’s ability to listen to conversations
      unwarranted isn’t common knowledge, do you think consumers would refrain
      from purchasing these systems if adequately informed of this aspect?
    </p>
    <p>
      This week's reading was particularly interesting to me, mostly because I
      was able to personally relate to it. Mina, Steyerl, and Menkman all
      advocated for the idea that the current state of the internet and its
      content are able to push political agendas and accurately mirror the
      current human condition. Mina argues this through the idea of memes,
      claiming memes can be used in order to push political opinions in parts of
      the world where public dissent could be physically dangerous. Not only is
      this true, but I personally have seen political memes genuinely convert
      people to different ideologies. Steyerl and Menkman both make a related
      statement, regarding the quality of visual content on the internet.
      Steyerl mentions a “poor image” or a heavily edited and remixed image by
      users over time and explains how though its quality degrades, not only is
      it inclusive of all voices but also could be used to push both positive
      and negative messages. Menkman takes this further, questioning
      high-resolution images in general. They claim that high-resolution images
      hold larger meaning, socially, and that glitched formats are a way to
      rebel against this social construct. Are political meme pages, especially
      on Instagram, beneficial or harmful to their respective movements? Are
      there any “requirements” or guidelines to differentiating a “poor image”
      from a “regular image”? In Menkman’s ideal internet culture, they claim a
      glitched aesthetic would help negate high-resolution images, but could you
      see the glitched aesthetic becoming the new high-resolution image?
    </p>
    <p>
      The central theme of this week’s talks/readings revolved around the idea
      of misrepresentations and oppression in algorithms and technology. Joy
      Buolamwini brought up the issue of facial recognition software in a
      project of hers. This type of facial recognition software has also been
      used to identify criminals, however, this type of technology often ends up
      misidentifying citizens as criminals. Boulamwini offers a solution, which
      requires us to consider who codes, how they code, and why they code. Mimi
      Onuoha speaks on a similar topic, but more specifically on how data has
      been used to fight oppression. She brings up a data collection study on
      race in the play industry, and how aapi and bipoc rarely ever had any
      roles in plays. With the data collected from this study, actors across the
      country were able to use this data to showcase this inequality and land
      more parts. Stephanie Dinkins also provides a solution to algorithmic
      oppression called “afro-now-ism”, which from my understanding was an idea
      of a change into bipoc-lead technology. When do you think the first forms
      of technological oppression emerged? With what technology? Is
      technological oppression a product of individuals or the system in which
      they work? What are some factors that lead to technological oppression?
    </p>
    <p>
      Morehshin Allahyari speaks on the decolonization and reconfiguring of data
      and coding. They focus on the destruction of ancient artifacts and statues
      in the middle east, performed by ISIS in order to destroy “idols”.
      Allahyari decided to recreate these destroyed artifacts using images of
      the object from different angles alongside programs and algorithms. They
      reference an idea of additivism- a combination of additive and activism, a
      sort of call to arms in order to “transmute digital forms through the
      material world into human scale actions and effects”. This idea of
      additivism and use of data in favor of justice applies to Olivia Ross’
      work, role as a cyber doula- a sort of data healer working to reverse the
      effects of data trauma. This push for non-violent coding not only opposes
      exclusive algorithms from last week's reading, but goes further to push
      back against more systemic issues from global capitalism to imperialism to
      white supremacy. What other forms of additivism have we seen from other
      artists? Is data healing enough to fight back against data trauma? Could
      violent coding in response to violent coding be more effective than
      non-violent coding?
    </p>
    <p>
      AriCiano’s “Omni-Specialized Design for Beautiful Futures”, concerns the
      development of future technology, spaces, and everything in general
      through a sustainable lens. They mention designing with and not for
      marginalized groups, which reminds me of Joy Buolamwini’s, “How I’m
      fighting bias in algorithms” Ted talk, in which they speak on the need for
      aapi and bipoc in the process of creating algorithms and code. The second
      article “The activist dismantling racist police algorithms” by Tate
      Ryan-Mosley and Jennifer Strong follows Hamid Khan, the founder of the
      Stop LAPD Spying Coalition. Khan details the systemic issues within the
      policing system and how there’s no such thing as surveillance without
      bias. Khan also emphasizes their disbelief in the idea of reform, and
      considers themselves an abolitionist group, as reform rarely ever works. I
      was interested by both of these articles, however, the article on Khan
      definitely intrigued me much more. The idea that abolition and reform can
      be separated is one that never really occurred to me. Is the abolition of
      the system not considered a form of reform? If not, would reform and a
      slow transition into a better future not be more tangible than a sudden
      abolition of the system? Are there any forms of circular design we see
      today? (aside from recycling) And is a worldwide system of circular design
      possible?
    </p>
  </body>
</html>
